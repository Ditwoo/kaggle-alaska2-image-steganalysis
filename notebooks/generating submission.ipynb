{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics\n",
    "\n",
    "import albumentations as alb\n",
    "import albumentations.pytorch\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/site-packages/nbformat/notebooknode.py:4: DeprecationWarning:\n",
      "\n",
      "Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "\n",
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:1658: DeprecationWarning:\n",
      "\n",
      "This class has been deprecated. Please use ImageCompression\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import BinaryEfficientNet\n",
    "from src.datasets import ImagesDataset\n",
    "\n",
    "ttas = [\n",
    "    # original\n",
    "    alb.Compose([\n",
    "        alb.Resize(512, 512),\n",
    "        alb.Normalize(),\n",
    "        alb.pytorch.ToTensorV2(),\n",
    "    ]),\n",
    "    # horizontal flipped\n",
    "    alb.Compose([\n",
    "        alb.Resize(512, 512),\n",
    "        alb.HorizontalFlip(p=1),\n",
    "        alb.Normalize(),\n",
    "        alb.pytorch.ToTensorV2(),\n",
    "    ]),\n",
    "    # vertical flipped\n",
    "    alb.Compose([\n",
    "        alb.Resize(512, 512),\n",
    "        alb.VerticalFlip(p=1),\n",
    "        alb.Normalize(),\n",
    "        alb.pytorch.ToTensorV2(),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "len(ttas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = BinaryEfficientNet(\"efficientnet-b0\")\n",
    "model.load_state_dict(\n",
    "    torch.load(\"../logs/efficientnet-b0-magic-constant/checkpoints/best.pth\", map_location=\"cpu\")[\"model_state_dict\"]\n",
    ")\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " ['../data/resized_data/Test/1787.jpg', '../data/resized_data/Test/0312.jpg'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = glob.glob(\"../data/resized_data/Test/*.jpg\")\n",
    "\n",
    "len(test_images), test_images[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA index: 1: 100%|██████████| 79/79 [00:36<00:00,  2.15it/s]\n",
      "TTA index: 2: 100%|██████████| 79/79 [00:36<00:00,  2.16it/s]\n",
      "TTA index: 3: 100%|██████████| 79/79 [00:36<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "tta_preds = []\n",
    "for transform_idx, transform in enumerate(ttas, 1):\n",
    "\n",
    "    dataset = ImagesDataset(test_images, transforms=transform)\n",
    "    loader = DataLoader(dataset, batch_size=64, num_workers=16)\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f\"TTA index - {transform_idx}\"):\n",
    "            batch = batch.to(device)\n",
    "            out = torch.sigmoid(model(batch)).detach().cpu().numpy().flatten()\n",
    "            preds.append(out)\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    tta_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000,),\n",
       " array([0.5759569 , 0.76441056, 0.6511685 , ..., 0.80173016, 0.573744  ,\n",
       "        0.66806084], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pred = np.mean(np.stack(tta_preds), 0)\n",
    "avg_pred.shape, avg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001.jpg</td>\n",
       "      <td>0.694623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0002.jpg</td>\n",
       "      <td>0.648925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0003.jpg</td>\n",
       "      <td>0.724082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0004.jpg</td>\n",
       "      <td>0.686711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0005.jpg</td>\n",
       "      <td>0.648012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id     Label\n",
       "0  0001.jpg  0.694623\n",
       "1  0002.jpg  0.648925\n",
       "2  0003.jpg  0.724082\n",
       "3  0004.jpg  0.686711\n",
       "4  0005.jpg  0.648012"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = ps.DataFrame.from_dict({\n",
    "    \"Id\": [file.rsplit(\"/\", 1)[1] for file in test_images],\n",
    "    \"Label\": avg_pred\n",
    "}).sort_values(by=\"Id\").reset_index(drop=True)\n",
    "\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../submissions/bin_en_b0_hvflip.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id,Label\n",
      "0001.jpg,0.6946228\n",
      "0002.jpg,0.64892507\n",
      "0003.jpg,0.7240815\n",
      "0004.jpg,0.6867114\n",
      "0005.jpg,0.6480124\n",
      "0006.jpg,0.75760317\n",
      "0007.jpg,0.8171317\n",
      "0008.jpg,0.6424361\n",
      "0009.jpg,0.5988344\n"
     ]
    }
   ],
   "source": [
    "!head ../submissions/bin_en_b0_hvflip.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('torch': conda)",
   "language": "python",
   "name": "python37464bittorchcondab46d9803850a4193b40c5aded830a323"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
