{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/site-packages/tqdm/std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/site-packages/nbformat/notebooknode.py:4: DeprecationWarning:\n",
      "\n",
      "Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "\n",
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/dmdr/anaconda3/envs/torch/lib/python3.7/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/dmdr/anaconda3/envs/torch/lib/python3.7/site-packages/torchvision/_C.so'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models import MulticlassEfficientNet\n",
    "from src.datasets import ImagesDataset\n",
    "from src.metrics import _alaska_weighted_auc\n",
    "from src.experiment import VALID_AUGMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = MulticlassEfficientNet(\"efficientnet-b3\", 4)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"../logs/efficientnet-b3-c4-grouped7/checkpoints/best.pth\",\n",
    "#         \"../logs/efficientnet-b0-magic-constant-continue2/checkpoints/best.pth\", \n",
    "        map_location=\"cpu\"\n",
    "    )[\"model_state_dict\"]\n",
    ")\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 4)\n",
      "1    45000\n",
      "0    15000\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>classes</th>\n",
       "      <th>folds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../data/resized_data/Cover/28292.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../data/resized_data/Cover/75472.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../data/resized_data/Cover/32819.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>../data/resized_data/Cover/42993.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>../data/resized_data/Cover/70794.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 images  labels  classes  folds\n",
       "0  ../data/resized_data/Cover/28292.jpg       0        0      0\n",
       "2  ../data/resized_data/Cover/75472.jpg       0        0      0\n",
       "3  ../data/resized_data/Cover/32819.jpg       0        0      0\n",
       "5  ../data/resized_data/Cover/42993.jpg       0        0      0\n",
       "6  ../data/resized_data/Cover/70794.jpg       0        0      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ps.read_csv(\"../data/combined_group.csv\")\n",
    "data = data[data[\"folds\"] == 0]\n",
    "data[\"images\"] = \"../\" + data[\"images\"]\n",
    "\n",
    "print(data.shape)\n",
    "print(data[\"labels\"].value_counts())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImagesDataset(data[\"images\"].values, transforms=VALID_AUGMENTATIONS)\n",
    "dataloader = DataLoader(dataset, batch_size=64, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [14:11<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        out = 1 - F.softmax(model(batch), dim=1).data.cpu().numpy()[:,0]\n",
    "        preds.append(out)\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.8259\n",
      "        AUC = 0.8806701222222222\n",
      "WeightedAUC = 0.9145383126984128\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "_preds = preds\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.75205\n",
      "        AUC = 0.8806701222222222\n",
      "WeightedAUC = 0.9145383126984128\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "\n",
    "_preds = preds ** 2\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.6919833333333333\n",
      "        AUC = 0.8806701222222222\n",
      "WeightedAUC = 0.9145383126984128\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "\n",
    "_preds = preds ** 4\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.6688666666666667\n",
      "        AUC = 0.8806701222222222\n",
      "WeightedAUC = 0.9145383126984128\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "\n",
    "_preds = preds ** 8\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## another checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = MulticlassEfficientNet(\"efficientnet-b3\", 4)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"../logs/efficientnet-b3-c4-grouped6/checkpoints/best.pth\",\n",
    "#         \"../logs/efficientnet-b0-magic-constant-continue2/checkpoints/best.pth\", \n",
    "        map_location=\"cpu\"\n",
    "    )[\"model_state_dict\"]\n",
    ")\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [13:37<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds2 = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        out = 1 - F.softmax(model(batch), dim=1).data.cpu().numpy()[:,0]\n",
    "        preds2.append(out)\n",
    "\n",
    "preds2 = np.concatenate(preds2)\n",
    "print(preds2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.8259\n",
      "        AUC = 0.8806701222222222\n",
      "WeightedAUC = 0.9145383126984128\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "_preds = preds\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.8248333333333333\n",
      "        AUC = 0.8795510903703704\n",
      "WeightedAUC = 0.913848753968254\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "_preds = preds2\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test power blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.8260666666666666\n",
      "        AUC = 0.8807713881481481\n",
      "WeightedAUC = 0.9146921444444446\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "_preds = (preds + preds2) / 2\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.82605\n",
      "        AUC = 0.8807900577777777\n",
      "WeightedAUC = 0.9147053989417989\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "_preds = (preds ** 2 + preds2 ** 2) / 2\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.25)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.68685\n",
      "        AUC = 0.8807708488888888\n",
      "WeightedAUC = 0.9146915682539684\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "_preds = (preds ** 4 + preds2 ** 4) / 2\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.662\n",
      "        AUC = 0.880747277037037\n",
      "WeightedAUC = 0.9146744814814814\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "_preds = (preds ** 8 + preds2 ** 8) / 2\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, _preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, _preds)\n",
    "accuracy = (labels == (_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {accuracy}')\n",
    "print(f'        AUC = {auc}')\n",
    "print(f'WeightedAUC = {weighted_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score on all train data (train + validation)\n",
    "\n",
    "**NOTE:** this score will be different from score on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.62635\n",
      "        AUC = 0.77973\n",
      "WeightedAUC = 0.84226\n"
     ]
    }
   ],
   "source": [
    "labels = data[\"labels\"].values\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, preds)\n",
    "weighted_auc = _alaska_weighted_auc(labels, preds)\n",
    "accuracy = (labels == (preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {round(accuracy, 5)}')\n",
    "print(f'        AUC = {round(auc, 5)}')\n",
    "print(f'WeightedAUC = {round(weighted_auc, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.85      0.53     15000\n",
      "           1       0.92      0.55      0.69     45000\n",
      "\n",
      "    accuracy                           0.63     60000\n",
      "   macro avg       0.65      0.70      0.61     60000\n",
      "weighted avg       0.79      0.63      0.65     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(labels, preds >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy - 0.5510222222222222\n",
      "Negative accuracy - 0.8523333333333334\n"
     ]
    }
   ],
   "source": [
    "pred_classes = (preds >= 0.5)\n",
    "\n",
    "print(\"Positive accuracy -\", (labels == pred_classes)[labels == 1].mean())\n",
    "print(\"Negative accuracy -\", (labels == pred_classes)[labels == 0].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Accuracy = 0.75417\n",
      "        AUC = 0.73491\n",
      "WeightedAUC = 0.80841\n"
     ]
    }
   ],
   "source": [
    "fold_labels = data[data[\"folds\"] == 0][\"labels\"].values\n",
    "fold_preds = preds[data[\"folds\"] == 0]\n",
    "\n",
    "\n",
    "auc = metrics.roc_auc_score(fold_labels, fold_preds)\n",
    "weighted_auc = _alaska_weighted_auc(fold_labels, fold_preds)\n",
    "accuracy = (fold_labels == (fold_preds >= 0.5)).mean()\n",
    "\n",
    "\n",
    "print(f'   Accuracy = {round(accuracy, 5)}')\n",
    "print(f'        AUC = {round(auc, 5)}')\n",
    "print(f'WeightedAUC = {round(weighted_auc, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.06      0.10     15000\n",
      "           1       0.76      0.99      0.86     45000\n",
      "\n",
      "    accuracy                           0.75     60000\n",
      "   macro avg       0.67      0.52      0.48     60000\n",
      "weighted avg       0.72      0.75      0.67     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(fold_labels, fold_preds >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive accuracy - 0.9872\n",
      "Negative accuracy - 0.05506666666666667\n"
     ]
    }
   ],
   "source": [
    "pred_classes = (fold_preds >= 0.5)\n",
    "\n",
    "print(\"Positive accuracy -\", (fold_labels == pred_classes)[fold_labels == 1].mean())\n",
    "print(\"Negative accuracy -\", (fold_labels == pred_classes)[fold_labels == 0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('torch': conda)",
   "language": "python",
   "name": "python37464bittorchcondab46d9803850a4193b40c5aded830a323"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
